{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h2>Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación</h2>\n",
    "<h3>Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2020</h3>\n",
    "<h3>Predicción de la Calidad de Servicio</h3>\n",
    "<h3>Introducción al Aprendizaje Automático</h3>\n",
    "</center>\n",
    "</left>\n",
    "<h4>Mentor: Martín Hunziker</h4>\n",
    "\n",
    "[Link Mentoria](https://sites.google.com/view/mentorias2020-diplodatos/ciencia-de-datos-aplicada-en-la-distribuci%C3%B3n-de-energ%C3%ADa-el%C3%A9ctrica?authuser=0).\n",
    "\n",
    "</left>\n",
    "</left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En la siguiente notebook, se presentará la consigna a seguir para el tercer práctico de la materia Introducción al Aprendizaje Automático y la segunda parte de la creación de variables. \n",
    "\n",
    "Como referencia para el análisis geográfico utilizaremos la notebook 2_0_Intro_Variables_georefrenciadas de Ramiro Caro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.get_cachedir()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPoint, MultiLineString\n",
    "import contextily as ctx\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, mean_squared_error, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.spatial import cKDTree\n",
    "np.random.seed(0)  # Para mayor determinismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_csv = './Dataset/group_ucbt_untrd_untrs_dist_v2.csv'\n",
    "data_path = './Dataset/ENF_6612_2018-12-31_M10_20190529-1610.gdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs = pd.read_csv(data_path_csv) #Cargamos el dataset del práctico 2\n",
    "ucbt_untrd_untrs.drop(columns=['Unnamed: 0'], axis=1,\n",
    "                          inplace=True)\n",
    "ssmt = gpd.read_file(data_path, driver='FileGDB', layer='SSDMT')\n",
    "untrd = gpd.read_file(data_path, driver='FileGDB', layer='UNTRD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigna para la creación de Features\n",
    "\n",
    "### I. Features Geográficas\n",
    "\n",
    "Continuando con lo iniciado en los análisis previos, vamos a trabajar con la generación de Features a partir de grafos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigna para Introducción al Aprendizaje Automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Preprocesamiento\n",
    "\n",
    "#### 1. Obtención del Dataset\n",
    "\n",
    "Trabajaremos con el Dataset aumentado con las variables que obtuvimos en el práctico 2 y en la creación de Features del presente práctico..\n",
    "\n",
    "\n",
    "#### 2. Normalización de Atributos\n",
    "\n",
    "Es posible que sea necesario normalizar las features de nuestro dataset, dado que muchos de los algoritmos de clasificación supervisada lo requieren. ¿En qué casos tendrá que implementarse normalización?\n",
    "\n",
    "Aplicar al datasets la normalización de atributos que consideren adecuada.\n",
    "\n",
    "#### 3. Mezca Aleatória y División en Train/Test\n",
    "\n",
    "Finalmente, están en condiciones de **dividir el dataset en Train y Test**, utilizando para este último conjunto un 20% de los datos disponibles. Previo a esta división, es recomendable que mezclen los datos aleatoriamente.\n",
    "De este modo, deberán obtener cuatro conjuntos de datos, para cada uno de los datasets: ```X_train```, ```X_test```, ```y_train``` y ```y_test```.\n",
    "\n",
    "### III. Aplicación de Modelos de Clasificación\n",
    "\n",
    "Una vez finalizada la etapa de preprocesamiento, se propone implementar diferentes modelos de clasificación, utilizando la librería Scikit-Learn:\n",
    "\n",
    "1. Perceptron. Utilizar el método Stochastic Gradient Descent.\n",
    "2. K Nearest Neighbors ó K Vecinos Más Cercanos.\n",
    "3. Regresión Logística. Utilizar el método Stochastic Gradient Descent.\n",
    "\n",
    "De estos tres tipos de modelos, cuál creen que es el más adecuado para nuestro caso de aplicación?\n",
    "\n",
    "**Elegir el modelo que consideren que mejor aplica a nuestro problema.** Para ello, recuerden que los pasos a seguir en la selección pueden esquematizarse como sigue:\n",
    "\n",
    "#### 1. Descripción de la Hipótesis\n",
    "\n",
    "¿Cuál es nuestro problema? ¿Cómo se caracteriza? ¿Cuál es la hipótesis?\n",
    "\n",
    "#### 2. Selección de Regularizador\n",
    "\n",
    " ¿Utilizarán algún regularizador?¿Cuál?\n",
    "\n",
    "#### 3. Selección de Función de Costo\n",
    "\n",
    "¿Cuál será la función de costo utilizada?\n",
    "\n",
    "#### 4. Justificación de las Selecciones\n",
    "\n",
    "¿Por qué eligieron el modelo, el regularizador y la función de costo previas?\n",
    "\n",
    "Finalmente, para el modelo selecionado:\n",
    "\n",
    "- Utilizar el método *Grid Search*, o de búsqueda exahustiva, con *cross-validation* para profundizar en la búsqueda y selección de hiperparámetros.\n",
    "- Calcular métricas sobre el conjunto de entrenamiento y de evaluación para los mejores parámetros obtenidos:\n",
    "    + Accuracy o exactitud\n",
    "    + Reporte de clasificación\n",
    "    + Confusion matrix o matriz de confusión (graficar como heatmap)\n",
    "    + Curva ROC y área bajo la curva (AUC).\n",
    "---\n",
    "\n",
    "Recuerden que la ciencia de datos es un **proceso circular, continuo y no lineal**. Es decir, si los datos requieren de mayor procesamiento para satisfacer las necesidades de algoritmos de ML (cualesquiera de ellos), vamos a volver a la etapa inicial para, por ejemplo, crear nuevas features, tomar decisiones diferentes sobre valores faltantes o valores atípicos (outliers), descartar features, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Análisis  Contenido (Cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Features geográficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pa-bOWcEhua5"
   },
   "source": [
    "Cargue el Dataset con las variables generadas en el práctico 2.\n",
    "\n",
    "#### Generación de grafos y calculo de rutas\n",
    "\n",
    "1 - Usando las técnicas mostradas en el notebook sobre procesamiento de información georeferenciada, construya un grafo basado en la capa de línea de distribición de media tensión:\n",
    "  - Utilize los puntos de conexión PCON_1 y PCON_2 como nodos, y los segmentos como edges.\n",
    "  - Adicione COMP y COD_ID como atributos de edge (aristas)\n",
    "  - Asocie cada transformador untrd con un nodo\n",
    "  - Asocie cada punto de conexión los circuitos de media tension (CTMT) con la subestación, a un nodo.\n",
    "\n",
    "2 - Seleccione al menos 5 métricas de grafo, calcule sus valores para los nodos asociados a cada fila y adicionelos como features al dataset.\n",
    "\n",
    "3 - Calcule la distancia de cada untrd a su correspondiente punto de conexión con la subestación, ponderando por COMP (longitud de segmento), utilize el parametro \"method\" para calcular diferentes tipos de distancias.\n",
    "Adicione los resultados como variables del dataset.\n",
    "\n",
    "4 - Calcule la ruta (secuencia de nodos) hasta la conexión con la subestación, y en base a esta calcule:\n",
    " - Resistencia eléctica total de cada conexión\n",
    " - Reactancia eléctrica de cada conexión.\n",
    " [Opcional]\n",
    " - Modulo y ángulo de la Impedancia.\n",
    " - Corriente Nonimal media a lo largo de la ruta\n",
    " - Corriente Maxima media del conductor a lo largo la ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG = nx.Graph()\n",
    "SG.add_weighted_edges_from(ssmt[['PN_CON_1','PN_CON_2','COMP']].values.tolist(), weight='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_attr_dict = {tuple((x[0], x[1])): x[2] for x in ssmt[['PN_CON_1','PN_CON_2','COD_ID']].values}\n",
    "nx.set_edge_attributes(SG, ID_attr_dict, 'SEG_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs.UNI_TR_D = ucbt_untrd_untrs.UNI_TR_D.astype(str)\n",
    "ucbt_untrd_untrs_with_metrics = pd.merge(untrd[['COD_ID', 'geometry', 'CTMT']], ucbt_untrd_untrs, how='inner', on=None,\n",
    "                                                left_on=['COD_ID'],\n",
    "                                                right_on=['UNI_TR_D'], sort=False,\n",
    "                                                copy=True, indicator=False,\n",
    "                                                validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrd_loc_array = [x.coords[0] for x in ucbt_untrd_untrs_with_metrics.geometry]\n",
    "#Cargamos los postes y con el algoritmo asociamos cada untrd a cada poste inicial como NODE y ENDNODE\n",
    "ponnot = gpd.read_file(data_path, driver='FileGDB', layer='PONNOT')\n",
    "#ponnot = ponnot.to_crs(epsg=31984)\n",
    "ponnot = ponnot[ponnot.COD_ID.isin(ssmt.PN_CON_1.tolist()+ssmt.PN_CON_2.tolist())] # solamente consideramos los ponnot donde estan conectados los segmentos de MT (ssdmt)\n",
    "ponnot_loc_array = [x.coords[0] for x in ponnot.geometry]\n",
    "\n",
    "pn_tree = cKDTree(ponnot_loc_array)\n",
    "pnd, pni = pn_tree.query(untrd_loc_array, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs_with_metrics['NODE'] = [ponnot.iloc[i].COD_ID for i in pni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctmt_endpoints = pd.read_csv('./Dataset/endpoint_utf.csv', sep =\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctmt_endpoints = pd.read_csv('./Dataset/endpoint_utf.csv', sep =\";\")\n",
    "ep_dict = {str(row.CTMT): str(row.PONNOT) for i,row in ctmt_endpoints.iterrows()}\n",
    "ucbt_untrd_untrs_with_metrics['ENDNODE'] = ucbt_untrd_untrs_with_metrics.CTMT.map(ep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando degree\n",
      "calculando neighbor degree\n",
      "calculando pagerank\n"
     ]
    }
   ],
   "source": [
    "print('calculando degree')\n",
    "g_degree = SG.degree(ucbt_untrd_untrs_with_metrics.NODE)\n",
    "\n",
    "print('calculando neighbor degree')\n",
    "g_avg_ndeg = nx.average_neighbor_degree(SG)\n",
    "\n",
    "print('calculando pagerank')\n",
    "g_pr = nx.pagerank(SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar al grafico como Atributo de los nodos\n",
    "nx.set_node_attributes(SG, g_degree, 'degree')\n",
    "nx.set_node_attributes(SG, g_avg_ndeg, 'avg_nei_degree')\n",
    "nx.set_node_attributes(SG, g_pr, 'pagerank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear valores a al dataframe de transformadores\n",
    "ucbt_untrd_untrs_with_metrics['g_degree'] = ucbt_untrd_untrs_with_metrics.NODE.map(g_degree)\n",
    "ucbt_untrd_untrs_with_metrics['g_avg_ndeg'] = ucbt_untrd_untrs_with_metrics.NODE.map(g_avg_ndeg)\n",
    "ucbt_untrd_untrs_with_metrics['g_pagerank'] = ucbt_untrd_untrs_with_metrics.NODE.map(g_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16177.061999999993"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.shortest_path_length(SG, ucbt_untrd_untrs_with_metrics.NODE[0], ucbt_untrd_untrs_with_metrics.ENDNODE[0], weight='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs_with_metrics['dist_to_trs'] = [nx.shortest_path_length(SG, trd.NODE, trd.ENDNODE, weight='length') for i, trd in ucbt_untrd_untrs_with_metrics.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16177.062\n",
       "1       16246.083\n",
       "2       16821.404\n",
       "3       17493.381\n",
       "4       14907.411\n",
       "          ...    \n",
       "3329    18705.213\n",
       "3330    18538.201\n",
       "3331    17748.824\n",
       "3332    18833.131\n",
       "3333    18043.850\n",
       "Name: dist_to_trs, Length: 3334, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucbt_untrd_untrs_with_metrics['dist_to_trs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrd_node_paths = [nx.shortest_path(SG, trd.NODE, trd.ENDNODE) for i, trd in ucbt_untrd_untrs_with_metrics.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 39),\n",
       " Index(['DIST', 'GEOM_CAB', 'FORM_CAB', 'MAT_FAS_1', 'MAT_FAS_2', 'MAT_FAS_3',\n",
       "        'MAT_NEU', 'ISO_FAS_1', 'ISO_FAS_2', 'ISO_FAS_3', 'ISO_NEU', 'CND_FAS',\n",
       "        'R1', 'X1', 'FTRCNV', 'CNOM', 'CMAX', 'CM_FAS', 'TUC_FAS', 'A1_FAS',\n",
       "        'A2_FAS', 'A3_FAS', 'A4_FAS', 'A5_FAS', 'A6_FAS', 'CM_NEU', 'TUC_NEU',\n",
       "        'A1_NEU', 'A2_NEU', 'A3_NEU', 'A4_NEU', 'A5_NEU', 'A6_NEU', 'DESCR',\n",
       "        'BIT_FAS_1', 'BIT_FAS_2', 'BIT_FAS_3', 'BIT_NEU', 'geometry'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carguemos la tabla de consumidores de baja tension denominada UCBT\n",
    "cond = gpd.read_file(data_path, driver='FileGDB', layer='SEGCON')\n",
    "cond.set_index('COD_ID', inplace=True)\n",
    "cond.shape, cond.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond= cond[['R1','X1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrd_seg_paths = [[SG.edges[path[i-1:i+1]]['SEG_ID'] for i in range(1,len(path))] for path in untrd_node_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmt.set_index('COD_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmt = ssmt.join(cond, on='TIP_CND', how='left')\n",
    "ssmt['R'] = ssmt.R1 * ssmt.COMP / 1000\n",
    "ssmt['X'] = ssmt.X1 * ssmt.COMP / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrd_ele = pd.DataFrame([ssmt[['COMP','R','X']].loc[r].sum().to_list() for r in untrd_seg_paths], index=ucbt_untrd_untrs_with_metrics.index, columns=['COMP','R','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_ID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>CTMT</th>\n",
       "      <th>UNI_TR_D</th>\n",
       "      <th>GRU_TAR</th>\n",
       "      <th>DIC</th>\n",
       "      <th>FIC</th>\n",
       "      <th>ENE_MED</th>\n",
       "      <th>ENE_MAX</th>\n",
       "      <th>UNI_TR_S</th>\n",
       "      <th>...</th>\n",
       "      <th>ENDNODE</th>\n",
       "      <th>g_degree</th>\n",
       "      <th>g_avg_ndeg</th>\n",
       "      <th>g_pagerank</th>\n",
       "      <th>dist_to_trs</th>\n",
       "      <th>COMP</th>\n",
       "      <th>R</th>\n",
       "      <th>X</th>\n",
       "      <th>impedancia</th>\n",
       "      <th>angulo_impedancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26877970</td>\n",
       "      <td>POINT (-42.59528 -22.19312)</td>\n",
       "      <td>27117490</td>\n",
       "      <td>26877970</td>\n",
       "      <td>1</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>274.0</td>\n",
       "      <td>27707625</td>\n",
       "      <td>...</td>\n",
       "      <td>27707667</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>16177.062</td>\n",
       "      <td>16211.275</td>\n",
       "      <td>10.679279</td>\n",
       "      <td>6.491497</td>\n",
       "      <td>12.497461</td>\n",
       "      <td>0.546178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26877971</td>\n",
       "      <td>POINT (-42.59618 -22.19249)</td>\n",
       "      <td>27117490</td>\n",
       "      <td>26877971</td>\n",
       "      <td>1</td>\n",
       "      <td>49.560000</td>\n",
       "      <td>11.00</td>\n",
       "      <td>112.166667</td>\n",
       "      <td>136.0</td>\n",
       "      <td>27707625</td>\n",
       "      <td>...</td>\n",
       "      <td>27707667</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>16246.083</td>\n",
       "      <td>16280.296</td>\n",
       "      <td>10.786330</td>\n",
       "      <td>6.522350</td>\n",
       "      <td>12.604998</td>\n",
       "      <td>0.543858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26877972</td>\n",
       "      <td>POINT (-42.59800 -22.19074)</td>\n",
       "      <td>27117490</td>\n",
       "      <td>26877972</td>\n",
       "      <td>1</td>\n",
       "      <td>43.265000</td>\n",
       "      <td>10.25</td>\n",
       "      <td>59.354167</td>\n",
       "      <td>519.0</td>\n",
       "      <td>27707625</td>\n",
       "      <td>...</td>\n",
       "      <td>27707667</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>16821.404</td>\n",
       "      <td>16855.617</td>\n",
       "      <td>11.678653</td>\n",
       "      <td>6.779518</td>\n",
       "      <td>13.503807</td>\n",
       "      <td>0.525962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26877973</td>\n",
       "      <td>POINT (-42.60002 -22.18566)</td>\n",
       "      <td>27117490</td>\n",
       "      <td>26877973</td>\n",
       "      <td>1</td>\n",
       "      <td>25.036667</td>\n",
       "      <td>8.00</td>\n",
       "      <td>92.444444</td>\n",
       "      <td>343.0</td>\n",
       "      <td>27707625</td>\n",
       "      <td>...</td>\n",
       "      <td>27707667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>17493.381</td>\n",
       "      <td>17527.594</td>\n",
       "      <td>12.720890</td>\n",
       "      <td>7.079892</td>\n",
       "      <td>14.558362</td>\n",
       "      <td>0.507863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26877977</td>\n",
       "      <td>POINT (-42.60092 -22.21269)</td>\n",
       "      <td>27117490</td>\n",
       "      <td>26877977</td>\n",
       "      <td>1</td>\n",
       "      <td>62.680000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>37.708333</td>\n",
       "      <td>130.0</td>\n",
       "      <td>27707625</td>\n",
       "      <td>...</td>\n",
       "      <td>27707667</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>14907.411</td>\n",
       "      <td>14941.624</td>\n",
       "      <td>7.934969</td>\n",
       "      <td>5.943998</td>\n",
       "      <td>9.914375</td>\n",
       "      <td>0.642918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>26876494</td>\n",
       "      <td>POINT (-42.32841 -22.37498)</td>\n",
       "      <td>27117483</td>\n",
       "      <td>26876494</td>\n",
       "      <td>1</td>\n",
       "      <td>62.690000</td>\n",
       "      <td>15.00</td>\n",
       "      <td>31.166667</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27707534</td>\n",
       "      <td>...</td>\n",
       "      <td>27707554</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>18705.213</td>\n",
       "      <td>18705.213</td>\n",
       "      <td>7.987270</td>\n",
       "      <td>7.195785</td>\n",
       "      <td>10.750619</td>\n",
       "      <td>0.733316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>26876495</td>\n",
       "      <td>POINT (-42.31524 -22.31688)</td>\n",
       "      <td>27117483</td>\n",
       "      <td>26876495</td>\n",
       "      <td>1</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>86.416667</td>\n",
       "      <td>164.0</td>\n",
       "      <td>27707534</td>\n",
       "      <td>...</td>\n",
       "      <td>27707554</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>18538.201</td>\n",
       "      <td>18538.201</td>\n",
       "      <td>8.357406</td>\n",
       "      <td>7.175402</td>\n",
       "      <td>11.015109</td>\n",
       "      <td>0.709447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>26876496</td>\n",
       "      <td>POINT (-42.30362 -22.31482)</td>\n",
       "      <td>27117483</td>\n",
       "      <td>26876496</td>\n",
       "      <td>1</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>80.916667</td>\n",
       "      <td>89.0</td>\n",
       "      <td>27707534</td>\n",
       "      <td>...</td>\n",
       "      <td>27707554</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>17748.824</td>\n",
       "      <td>17748.824</td>\n",
       "      <td>7.808364</td>\n",
       "      <td>6.843330</td>\n",
       "      <td>10.382761</td>\n",
       "      <td>0.719628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>26876497</td>\n",
       "      <td>POINT (-42.30930 -22.37747)</td>\n",
       "      <td>27117483</td>\n",
       "      <td>26876497</td>\n",
       "      <td>1</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>11.00</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>343.0</td>\n",
       "      <td>27707534</td>\n",
       "      <td>...</td>\n",
       "      <td>27707554</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>18833.131</td>\n",
       "      <td>18833.131</td>\n",
       "      <td>9.342956</td>\n",
       "      <td>7.367089</td>\n",
       "      <td>11.898102</td>\n",
       "      <td>0.667700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>26876498</td>\n",
       "      <td>POINT (-42.28612 -22.32659)</td>\n",
       "      <td>27117483</td>\n",
       "      <td>26876498</td>\n",
       "      <td>1</td>\n",
       "      <td>27.330000</td>\n",
       "      <td>11.00</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>305.0</td>\n",
       "      <td>27707534</td>\n",
       "      <td>...</td>\n",
       "      <td>27707554</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>18043.850</td>\n",
       "      <td>18043.850</td>\n",
       "      <td>8.154726</td>\n",
       "      <td>6.961758</td>\n",
       "      <td>10.722203</td>\n",
       "      <td>0.706643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3334 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        COD_ID                     geometry      CTMT  UNI_TR_D  GRU_TAR  \\\n",
       "0     26877970  POINT (-42.59528 -22.19312)  27117490  26877970        1   \n",
       "1     26877971  POINT (-42.59618 -22.19249)  27117490  26877971        1   \n",
       "2     26877972  POINT (-42.59800 -22.19074)  27117490  26877972        1   \n",
       "3     26877973  POINT (-42.60002 -22.18566)  27117490  26877973        1   \n",
       "4     26877977  POINT (-42.60092 -22.21269)  27117490  26877977        1   \n",
       "...        ...                          ...       ...       ...      ...   \n",
       "3329  26876494  POINT (-42.32841 -22.37498)  27117483  26876494        1   \n",
       "3330  26876495  POINT (-42.31524 -22.31688)  27117483  26876495        1   \n",
       "3331  26876496  POINT (-42.30362 -22.31482)  27117483  26876496        1   \n",
       "3332  26876497  POINT (-42.30930 -22.37747)  27117483  26876497        1   \n",
       "3333  26876498  POINT (-42.28612 -22.32659)  27117483  26876498        1   \n",
       "\n",
       "            DIC    FIC     ENE_MED  ENE_MAX  UNI_TR_S  ...   ENDNODE g_degree  \\\n",
       "0     14.950000   7.00  189.000000    274.0  27707625  ...  27707667        1   \n",
       "1     49.560000  11.00  112.166667    136.0  27707625  ...  27707667        1   \n",
       "2     43.265000  10.25   59.354167    519.0  27707625  ...  27707667        2   \n",
       "3     25.036667   8.00   92.444444    343.0  27707625  ...  27707667        1   \n",
       "4     62.680000  10.00   37.708333    130.0  27707625  ...  27707667        1   \n",
       "...         ...    ...         ...      ...       ...  ...       ...      ...   \n",
       "3329  62.690000  15.00   31.166667     48.0  27707534  ...  27707554        2   \n",
       "3330  16.150000   6.00   86.416667    164.0  27707534  ...  27707554        2   \n",
       "3331  16.150000   6.00   80.916667     89.0  27707534  ...  27707554        1   \n",
       "3332  19.580000  11.00  264.500000    343.0  27707534  ...  27707554        1   \n",
       "3333  27.330000  11.00   61.750000    305.0  27707534  ...  27707554        2   \n",
       "\n",
       "     g_avg_ndeg  g_pagerank  dist_to_trs       COMP          R         X  \\\n",
       "0           4.0    0.000022    16177.062  16211.275  10.679279  6.491497   \n",
       "1           4.0    0.000022    16246.083  16280.296  10.786330  6.522350   \n",
       "2           2.0    0.000040    16821.404  16855.617  11.678653  6.779518   \n",
       "3           3.0    0.000023    17493.381  17527.594  12.720890  7.079892   \n",
       "4           2.0    0.000026    14907.411  14941.624   7.934969  5.943998   \n",
       "...         ...         ...          ...        ...        ...       ...   \n",
       "3329        2.0    0.000041    18705.213  18705.213   7.987270  7.195785   \n",
       "3330        2.0    0.000044    18538.201  18538.201   8.357406  7.175402   \n",
       "3331        3.0    0.000023    17748.824  17748.824   7.808364  6.843330   \n",
       "3332        2.0    0.000025    18833.131  18833.131   9.342956  7.367089   \n",
       "3333        2.5    0.000041    18043.850  18043.850   8.154726  6.961758   \n",
       "\n",
       "      impedancia angulo_impedancia  \n",
       "0      12.497461          0.546178  \n",
       "1      12.604998          0.543858  \n",
       "2      13.503807          0.525962  \n",
       "3      14.558362          0.507863  \n",
       "4       9.914375          0.642918  \n",
       "...          ...               ...  \n",
       "3329   10.750619          0.733316  \n",
       "3330   11.015109          0.709447  \n",
       "3331   10.382761          0.719628  \n",
       "3332   11.898102          0.667700  \n",
       "3333   10.722203          0.706643  \n",
       "\n",
       "[3334 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ucbt_untrd_untrs_with_metrics[['COMP','R','X']] = untrd_ele\n",
    "\n",
    "ucbt_untrd_untrs_with_metrics['impedancia'] = ((ucbt_untrd_untrs_with_metrics['R'])**2 + (ucbt_untrd_untrs_with_metrics['X'])**2)**(1/2)\n",
    "ucbt_untrd_untrs_with_metrics['angulo_impedancia'] = np.arctan(ucbt_untrd_untrs_with_metrics['X'] / ucbt_untrd_untrs_with_metrics['R'])\n",
    "ucbt_untrd_untrs_with_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalización de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar al dataset la normalización de atributos que consideren adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pueden utilizar los siguientes métodos, por ejemplo:\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "standard_scaler = preprocessing.StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mezca Aleatória y División en Train/Test\n",
    "\n",
    "Primeramente, deberán mezclar los datos aleatoriamente. Luego, para dividir en Train/Test el dataset, aplicar el split utilizando un 20% de datos para este último.\n",
    "\n",
    "En este punto, deberán obtener cuatro conjuntos de datos, para ambos datasets: ```X_train```, ```X_test```, ```y_train``` y ```y_test```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Aplicación de Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perceptron\n",
    "A continuación se aplicará un clasificador Perceptrón.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COD_ID', 'geometry', 'CTMT', 'UNI_TR_D', 'GRU_TAR', 'DIC', 'FIC',\n",
       "       'ENE_MED', 'ENE_MAX', 'UNI_TR_S', 'ARE_LOC', 'geometry_untrd',\n",
       "       'geometry_untrs', 'EUC_DIST_UNTRS', 'EUC_DIST_CENT', 'EUC_DIST_PRIMARY',\n",
       "       'EUC_DIST_SECONDARY', 'TIEMPO_MIN', 'DISTANCIA_KM', 'NODE', 'ENDNODE',\n",
       "       'g_degree', 'g_avg_ndeg', 'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X',\n",
       "       'impedancia', 'angulo_impedancia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucbt_untrd_untrs_with_metrics.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs_with_metrics = pd.get_dummies(ucbt_untrd_untrs_with_metrics, columns=['GRU_TAR'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucbt_untrd_untrs_with_metrics['ARE_LOC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIC</th>\n",
       "      <th>FIC</th>\n",
       "      <th>ENE_MED</th>\n",
       "      <th>ENE_MAX</th>\n",
       "      <th>UNI_TR_S</th>\n",
       "      <th>ARE_LOC</th>\n",
       "      <th>EUC_DIST_UNTRS</th>\n",
       "      <th>EUC_DIST_CENT</th>\n",
       "      <th>EUC_DIST_PRIMARY</th>\n",
       "      <th>EUC_DIST_SECONDARY</th>\n",
       "      <th>...</th>\n",
       "      <th>g_avg_ndeg</th>\n",
       "      <th>g_pagerank</th>\n",
       "      <th>dist_to_trs</th>\n",
       "      <th>COMP</th>\n",
       "      <th>R</th>\n",
       "      <th>X</th>\n",
       "      <th>impedancia</th>\n",
       "      <th>angulo_impedancia</th>\n",
       "      <th>GRU_TAR_2</th>\n",
       "      <th>GRU_TAR_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3.334000e+03</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "      <td>3334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.575886</td>\n",
       "      <td>7.593354</td>\n",
       "      <td>0.367569</td>\n",
       "      <td>0.095926</td>\n",
       "      <td>3.245994e+07</td>\n",
       "      <td>0.554889</td>\n",
       "      <td>0.260111</td>\n",
       "      <td>0.320440</td>\n",
       "      <td>0.200438</td>\n",
       "      <td>0.170131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199110</td>\n",
       "      <td>0.259652</td>\n",
       "      <td>0.261482</td>\n",
       "      <td>0.254407</td>\n",
       "      <td>0.192423</td>\n",
       "      <td>0.242545</td>\n",
       "      <td>0.209833</td>\n",
       "      <td>0.755220</td>\n",
       "      <td>0.049790</td>\n",
       "      <td>0.035993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.964956</td>\n",
       "      <td>6.608679</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.131142</td>\n",
       "      <td>1.508740e+07</td>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.189484</td>\n",
       "      <td>0.231923</td>\n",
       "      <td>0.253354</td>\n",
       "      <td>0.169011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115436</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.198185</td>\n",
       "      <td>0.207894</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>0.179550</td>\n",
       "      <td>0.217544</td>\n",
       "      <td>0.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.770753e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.442833</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.286764</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>2.770753e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102763</td>\n",
       "      <td>0.136958</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>0.085538</td>\n",
       "      <td>0.083296</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>0.076659</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.520000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.374506</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>2.770775e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232410</td>\n",
       "      <td>0.266189</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>0.121979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.337429</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.196217</td>\n",
       "      <td>0.119408</td>\n",
       "      <td>0.184758</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.742856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.827500</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.439146</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>2.770786e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372916</td>\n",
       "      <td>0.460273</td>\n",
       "      <td>0.306615</td>\n",
       "      <td>0.255093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.375304</td>\n",
       "      <td>0.389537</td>\n",
       "      <td>0.376872</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.351554</td>\n",
       "      <td>0.307712</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>163.100000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.034524e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.149996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DIC          FIC      ENE_MED      ENE_MAX      UNI_TR_S  \\\n",
       "count  3334.000000  3334.000000  3334.000000  3334.000000  3.334000e+03   \n",
       "mean     18.575886     7.593354     0.367569     0.095926  3.245994e+07   \n",
       "std      22.964956     6.608679     0.160641     0.131142  1.508740e+07   \n",
       "min       0.000000     0.000000     0.000000     0.000000  2.770753e+07   \n",
       "25%       2.442833     2.200000     0.286764     0.006355  2.770753e+07   \n",
       "50%       9.520000     6.000000     0.374506     0.028123  2.770775e+07   \n",
       "75%      25.827500    11.000000     0.439146     0.148716  2.770786e+07   \n",
       "max     163.100000    44.500000     1.000000     1.000000  8.034524e+07   \n",
       "\n",
       "           ARE_LOC  EUC_DIST_UNTRS  EUC_DIST_CENT  EUC_DIST_PRIMARY  \\\n",
       "count  3334.000000     3334.000000    3334.000000       3334.000000   \n",
       "mean      0.554889        0.260111       0.320440          0.200438   \n",
       "std       0.497053        0.189484       0.231923          0.253354   \n",
       "min       0.000000        0.000000       0.000000          0.000000   \n",
       "25%       0.000000        0.102763       0.136958          0.012974   \n",
       "50%       1.000000        0.232410       0.266189          0.077176   \n",
       "75%       1.000000        0.372916       0.460273          0.306615   \n",
       "max       1.000000        1.000000       1.000000          1.000000   \n",
       "\n",
       "       EUC_DIST_SECONDARY  ...   g_avg_ndeg   g_pagerank  dist_to_trs  \\\n",
       "count         3334.000000  ...  3334.000000  3334.000000  3334.000000   \n",
       "mean             0.170131  ...     0.199110     0.259652     0.261482   \n",
       "std              0.169011  ...     0.115436     0.143839     0.218651   \n",
       "min              0.000000  ...     0.000000     0.000000     0.000000   \n",
       "25%              0.040078  ...     0.142857     0.100438     0.085538   \n",
       "50%              0.121979  ...     0.142857     0.337429     0.199608   \n",
       "75%              0.255093  ...     0.285714     0.375304     0.389537   \n",
       "max              1.000000  ...     1.000000     1.000000     1.000000   \n",
       "\n",
       "              COMP            R            X   impedancia  angulo_impedancia  \\\n",
       "count  3334.000000  3334.000000  3334.000000  3334.000000        3334.000000   \n",
       "mean      0.254407     0.192423     0.242545     0.209833           0.755220   \n",
       "std       0.212894     0.198185     0.207894     0.198534           0.179550   \n",
       "min       0.000000     0.000000     0.000000     0.000000           0.352911   \n",
       "25%       0.083296     0.043699     0.076659     0.056696           0.616641   \n",
       "50%       0.196217     0.119408     0.184758     0.145195           0.742856   \n",
       "75%       0.376872     0.288506     0.351554     0.307712           0.886667   \n",
       "max       1.000000     1.000000     1.000000     1.000000           1.149996   \n",
       "\n",
       "         GRU_TAR_2    GRU_TAR_3  \n",
       "count  3334.000000  3334.000000  \n",
       "mean      0.049790     0.035993  \n",
       "std       0.217544     0.186300  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucbt_untrd_untrs_with_metrics[['ENE_MED', 'ENE_MAX', 'R', 'X', 'impedancia', 'EUC_DIST_UNTRS',\n",
    "                               'EUC_DIST_CENT', 'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY',\n",
    "                               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "                               'g_degree', 'g_avg_ndeg',\n",
    "                               'g_pagerank', 'dist_to_trs', 'COMP']] = min_max_scaler.fit_transform(ucbt_untrd_untrs_with_metrics[['ENE_MED', 'ENE_MAX', 'R', 'X', 'impedancia', 'EUC_DIST_UNTRS',\n",
    "                               'EUC_DIST_CENT', 'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "                               'TIEMPO_MIN', 'DISTANCIA_KM', \n",
    "                               'g_degree', 'g_avg_ndeg',\n",
    "                               'g_pagerank', 'dist_to_trs', 'COMP']])\n",
    "ucbt_untrd_untrs_with_metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos una nueva columna llamada DIC_above que representa un 1 o un 0 en caso de que dicha fila, la DIC sea mayor al promedio será 1, de lo contrario 0.\n",
    "ucbt_untrd_untrs_with_metrics['DIC_above'] = np.where(ucbt_untrd_untrs_with_metrics['DIC'] > ucbt_untrd_untrs_with_metrics['DIC'].mean(), 1, 0)\n",
    "#Agregamos una nueva columna llamada FIC_above que representa un 1 o un 0 en caso de que dicha fila, la FIC sea mayor al promedio será 1, de lo contrario 0.\n",
    "ucbt_untrd_untrs_with_metrics['FIC_above'] = np.where(ucbt_untrd_untrs_with_metrics['FIC'] > ucbt_untrd_untrs_with_metrics['FIC'].mean(), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COD_ID', 'geometry', 'CTMT', 'UNI_TR_D', 'DIC', 'FIC', 'ENE_MED',\n",
       "       'ENE_MAX', 'UNI_TR_S', 'ARE_LOC', 'geometry_untrd', 'geometry_untrs',\n",
       "       'EUC_DIST_UNTRS', 'EUC_DIST_CENT', 'EUC_DIST_PRIMARY',\n",
       "       'EUC_DIST_SECONDARY', 'TIEMPO_MIN', 'DISTANCIA_KM', 'NODE', 'ENDNODE',\n",
       "       'g_degree', 'g_avg_ndeg', 'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X',\n",
       "       'impedancia', 'angulo_impedancia', 'GRU_TAR_2', 'GRU_TAR_3',\n",
       "       'DIC_above', 'FIC_above'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucbt_untrd_untrs_with_metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dividir el dataset, utilizar el siguiente módulo:\n",
    "\n",
    "_ds_shuff = shuffle(ucbt_untrd_untrs_with_metrics)\n",
    "\n",
    "# Y luego el módulo:\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', \n",
    "               'ENE_MAX', 'EUC_DIST_UNTRS',\n",
    "               'EUC_DIST_CENT', 'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg','g_pagerank', 'dist_to_trs', \n",
    "               'COMP', 'R', 'X', 'impedancia',\n",
    "               'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['DIC_above']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Notar que X e y son np.arrays. Además, pueden usar el parámetro que incluye train_test_split para mezclar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de las clasificaciones del perceptron para DIC:  0.7583864763640045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\diplo\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# En principio, pueden utilizar el módulo que sigue, con los parámetros por defecto y los que definan a continuación:\n",
    "\n",
    "#penalty = 0.001  \n",
    "alpha = 0.\n",
    "max_iter = 5\n",
    "#tol\n",
    "\n",
    "model = Perceptron(alpha = alpha, fit_intercept=True, max_iter = max_iter, shuffle=True, random_state=0, class_weight=None, warm_start=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_perceptron = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión de las clasificaciones del perceptron para DIC: \", acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de las clasificaciones del perceptron para FIC:  0.7981994589047485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\diplo\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Corremos el perceptron para la FIC\n",
    "y = _ds_shuff['FIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#penalty = 0.001  \n",
    "alpha = 0.\n",
    "max_iter = 5\n",
    "#tol\n",
    "\n",
    "model = Perceptron(alpha = alpha, fit_intercept=True, max_iter = max_iter, shuffle=True, random_state=0, class_weight=None, warm_start=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_perceptron = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión de las clasificaciones del perceptron para FIC: \", acc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se aplicará un clasificador K-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para 1 vecinos, tenemos: 0.79 de precisión.\n",
      "Para 2 vecinos, tenemos: 0.76 de precisión.\n",
      "Para 3 vecinos, tenemos: 0.80 de precisión.\n",
      "Para 4 vecinos, tenemos: 0.77 de precisión.\n",
      "Para 5 vecinos, tenemos: 0.81 de precisión.\n",
      "Para 6 vecinos, tenemos: 0.78 de precisión.\n",
      "Para 7 vecinos, tenemos: 0.81 de precisión.\n",
      "Para 8 vecinos, tenemos: 0.78 de precisión.\n",
      "Para 9 vecinos, tenemos: 0.80 de precisión.\n",
      "Para 10 vecinos, tenemos: 0.78 de precisión.\n",
      "Para 11 vecinos, tenemos: 0.80 de precisión.\n",
      "Para 12 vecinos, tenemos: 0.79 de precisión.\n",
      "Para 13 vecinos, tenemos: 0.80 de precisión.\n",
      "Para 14 vecinos, tenemos: 0.77 de precisión.\n",
      "Para 15 vecinos, tenemos: 0.79 de precisión.\n",
      "Para 16 vecinos, tenemos: 0.77 de precisión.\n",
      "Para 17 vecinos, tenemos: 0.79 de precisión.\n",
      "Para 18 vecinos, tenemos: 0.77 de precisión.\n",
      "Para 19 vecinos, tenemos: 0.79 de precisión.\n"
     ]
    }
   ],
   "source": [
    "metric = 'manhattan'\n",
    "\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX', \n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['DIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "for i in range(1, 20):\n",
    "    model = KNeighborsClassifier(n_neighbors=i, metric=metric)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_knn = recall_score(y_test, y_pred, average='macro')\n",
    "    print(\"Para \" + str(i) + \" vecinos, tenemos: %.2f\" % acc_knn + \" de precisión.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para 1 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 2 vecinos, tenemos: 0.83 de precisión.\n",
      "Para 3 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 4 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 5 vecinos, tenemos: 0.85 de precisión.\n",
      "Para 6 vecinos, tenemos: 0.85 de precisión.\n",
      "Para 7 vecinos, tenemos: 0.87 de precisión.\n",
      "Para 8 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 9 vecinos, tenemos: 0.86 de precisión.\n",
      "Para 10 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 11 vecinos, tenemos: 0.85 de precisión.\n",
      "Para 12 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 13 vecinos, tenemos: 0.85 de precisión.\n",
      "Para 14 vecinos, tenemos: 0.83 de precisión.\n",
      "Para 15 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 16 vecinos, tenemos: 0.82 de precisión.\n",
      "Para 17 vecinos, tenemos: 0.84 de precisión.\n",
      "Para 18 vecinos, tenemos: 0.82 de precisión.\n",
      "Para 19 vecinos, tenemos: 0.83 de precisión.\n"
     ]
    }
   ],
   "source": [
    "metric = 'manhattan'\n",
    "\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX', \n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['FIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "for i in range(1, 20):\n",
    "    model = KNeighborsClassifier(n_neighbors=i, metric=metric)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_knn = recall_score(y_test, y_pred, average='macro')\n",
    "    print(\"Para \" + str(i) + \" vecinos, tenemos: %.2f\" % acc_knn + \" de precisión.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión la regresión logística para DIC:  0.7458176307551195\n"
     ]
    }
   ],
   "source": [
    "#penalty =   # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "#alpha =   # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter = 10  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "#tol =   # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "_ds_shuff = shuffle(ucbt_untrd_untrs_with_metrics)\n",
    "\n",
    "# Y luego el módulo:\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX',\n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['DIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_logistic_regression = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión la regresión logística para DIC: \", acc_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión la regresión logística para FIC:  0.738313457008245\n"
     ]
    }
   ],
   "source": [
    "#penalty =   # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "#alpha =   # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter = 10  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "#tol =   # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "_ds_shuff = shuffle(ucbt_untrd_untrs_with_metrics)\n",
    "\n",
    "# Y luego el módulo:\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX',\n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['FIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_logistic_regression = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión la regresión logística para FIC: \", acc_logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo sería utilizando el método Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión la regresión logística para DIC:  0.7538055055738248\n"
     ]
    }
   ],
   "source": [
    "_ds_shuff = shuffle(ucbt_untrd_untrs_with_metrics)\n",
    "\n",
    "# Y luego el módulo:\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX',\n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['DIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_SGDClassifier_dic = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión la regresión logística para DIC: \", acc_SGDClassifier_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión la regresión logística para FIC:  0.8026113813319524\n"
     ]
    }
   ],
   "source": [
    "_ds_shuff = shuffle(ucbt_untrd_untrs_with_metrics)\n",
    "\n",
    "# Y luego el módulo:\n",
    "X = _ds_shuff[['ARE_LOC', 'GRU_TAR_2', 'GRU_TAR_3', 'ENE_MED', 'ENE_MAX',\n",
    "               'EUC_DIST_UNTRS', 'EUC_DIST_CENT',\n",
    "               'EUC_DIST_PRIMARY', 'EUC_DIST_SECONDARY', \n",
    "               'TIEMPO_MIN', 'DISTANCIA_KM',\n",
    "               'g_degree', 'g_avg_ndeg',\n",
    "       'g_pagerank', 'dist_to_trs', 'COMP', 'R', 'X', 'impedancia',\n",
    "       'angulo_impedancia']]\n",
    "\n",
    "y = _ds_shuff['FIC_above']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_SGDClassifier_fic = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precisión la regresión logística para FIC: \", acc_SGDClassifier_fic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selección del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Selección y Descripción de Hipótesis\n",
    "\n",
    "Describir el problema y la hipótesis del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Selección de Regularizador\n",
    "\n",
    " ¿Utilizarán algún regularizador?¿Cuál?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Selección de Función de Costo\n",
    "\n",
    "¿Cuál será la función de costo utilizada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Justificación de las Selecciones\n",
    "\n",
    "A continuación, se justifican las elecciones previas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Selección de Parámetros y Métricas Sobre el Conjunto de Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la selección de hiperparámetros, pueden utilizar GridSearch. Además, deben calcular las métricas solicitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de parámetros:\n",
      "{'C': 200, 'max_iter': 1000, 'tol': 0.005}\n",
      "\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       389\n",
      "           1       0.79      0.76      0.77       278\n",
      "\n",
      "    accuracy                           0.81       667\n",
      "   macro avg       0.81      0.80      0.81       667\n",
      "weighted avg       0.81      0.81      0.81       667\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para la búsqueda de los mejores parámetros, por ejemplo de logistic regression, pueden usar:\n",
    "exploring_params = {\n",
    "        'C': [0.5, 1, 2, 5, 10, 20, 100, 200], # Inversa del coeficiente de regularización\n",
    "        'max_iter': [1000, 5000, 10000],  # Cantidad de iteraciones\n",
    "        'tol': [0.005, 0.002, 0.001, 0.0001]  # Precisión del algoritmo\n",
    "    }\n",
    "\n",
    "m = LogisticRegression()\n",
    "n_cross_val =   5\n",
    "scoring = 'roc_auc'\n",
    "model = GridSearchCV(m, exploring_params, cv=n_cross_val, scoring=scoring)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "print()\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "print(\"================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de parámetros:\n",
      "{'metric': 'manhattan', 'n_neighbors': 8}\n",
      "\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       389\n",
      "           1       0.88      0.79      0.83       278\n",
      "\n",
      "    accuracy                           0.87       667\n",
      "   macro avg       0.87      0.86      0.86       667\n",
      "weighted avg       0.87      0.87      0.87       667\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para la búsqueda de los mejores parámetros, por ejemplo de K-NN, pueden usar:\n",
    "exploring_params = {\n",
    "        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 ,20], # Cantidad de vecinos.\n",
    "        'metric': ['cosine', 'euclidean', 'manhattan']  # Metricas\n",
    "    }\n",
    "\n",
    "m = KNeighborsClassifier()\n",
    "n_cross_val =   5\n",
    "scoring = 'roc_auc'\n",
    "model = GridSearchCV(m, exploring_params, cv=n_cross_val, scoring=scoring)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "print()\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "print(\"================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucbt_untrd_untrs_with_metrics.to_csv(\"./Dataset/ucbt_untrd_untrs_with_metrics_dist_v2_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
