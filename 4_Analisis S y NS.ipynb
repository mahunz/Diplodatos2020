{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h2>Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación</h2>\n",
    "<h3>Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2020</h3>\n",
    "<h3>Predicción de la Calidad de Servicio</h3>\n",
    "<h3>Aprendizaje Supervisado y No Supervisado</h3>\n",
    "</center>\n",
    "</left>\n",
    "<h4>Mentor: Martín Hunziker</h4>\n",
    "\n",
    "[Link Mentoria](https://sites.google.com/view/mentorias2020-diplodatos/ciencia-de-datos-aplicada-en-la-distribuci%C3%B3n-de-energ%C3%ADa-el%C3%A9ctrica?authuser=0).\n",
    "\n",
    "</left>\n",
    "</left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En la siguiente notebook, se presentará la consigna a seguir para el práctico de las materias Aprendizaje Supervisado y No Supervisado. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "H8KsnW0aZBSO",
    "outputId": "3166742e-8b30-4e33-aba0-664ac294e27e"
   },
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Puede que nos sirvan también\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)  # Para mayor determinismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYfP2gAkQ0UA"
   },
   "source": [
    "## 1.Carga de datos\n",
    "\n",
    "De los prácticos anteriores cargamos el dataset con las efatures georeferenciadas que calculamos.\n",
    "\n",
    "Exporta el dataframe obtenido en el ultimo practico a un csv y cargalo como dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dtj0qCSUQzGQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZP7ObB1GRT9J"
   },
   "source": [
    "__*Sugerencia:*__ eliminar variables que no aporten información por ejemplo:\n",
    "\n",
    "\n",
    "*   Indices y IDs\n",
    "*   Referencias a otras tablas\n",
    "*   Variables compuestas (listas, jsons, geometrias)\n",
    "\n",
    "Identifica las variables que cumplen este criterio y eliminelas del dataset.\n",
    "\n",
    "Eliminen la variable de salida que no van a utilizar FIC o DIC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQ89yxpfSDDN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpAzkeVtSdIy"
   },
   "source": [
    "## 2. Preprosecamiento y partición de datos\n",
    "\n",
    "Siempre se recomienda partir los datos antes de realizar el preprocesamiento, y guardar el pipeline de transformación para aplicar en operaciones futuras.\n",
    "\n",
    "Sin embargo algunas operaciones principalmente la codificación de variables puede realizarse antes de hacer la partición ya que no representa una interacción entre las filas.\n",
    "\n",
    "Genere una partición de datos en sets de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ0IBhiKWJuy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcB9QP1LYEPv"
   },
   "source": [
    "__**Recuerden:**__ *El procesamiento que debemos hacer sobre los datos esta relacionado con el algoritmo a implementar*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaSwP6dqXeNr"
   },
   "source": [
    "## 3. Preparación de datos para regresión lineal\n",
    "\n",
    "Los algoritmos de regresion solo aceptan entradas numéricas, por lo tanto el primer paso que debemos realizar es codificar las variables categóricas numericamente.\n",
    "\n",
    "Adicionalmente las diferencias en las dimensiones absolutas de las variables van a tener un impacto muy pronunciado en los coeficientes calculados por lo que tambien se recomienda realizar la normalizacion de las variables. \n",
    "\n",
    "Esto puede hacerse de varias maneras:\n",
    "\n",
    "*   Media/Mediana y desviacion standard\n",
    "*   Minimo y Maximo (Cuidado con los outliers)\n",
    "*   De 1 a -1\n",
    "\n",
    "Implemente una función o pipeline que aplique codificación de variables categóricas y luego normalización.\n",
    "\n",
    "__**Recuerden:**__ los parametros de normalización se calculan usando únicamente los valores de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsIoknucYDOD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0i5U-CAibQf-"
   },
   "source": [
    "## 4. Regresión lineal simple y regularizada.\n",
    "\n",
    "Con los datos preprocesados obtenidos en el punto anterior implemente una regresion lineal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgB0ItREcS10"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLJNebX5cT58"
   },
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Para evaluar el modelo calcule R cuadrado, error medio absoluto y error medio cuadrado. Tanto de entrenamiento como de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jxOOsbMcVJM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qs734DNnceT9"
   },
   "source": [
    "### Análisis de residuos\n",
    "\n",
    "Otro punto importante en la evaluación de los modelos de regresión, es no solo saber cuanto es el error sino como se distribuye. Para eso realizamos un análisis de residuos. Los residuos son simplemente las desviaciones de la predicción al valor real.\n",
    "\n",
    "Primero grafique la distribucion de los residuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAPxFUjNd8lE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zd0hbld0d_2L"
   },
   "source": [
    "Esta distribución debe estar centrada en cero y debería tender a ser simétrica.\n",
    "\n",
    "**A continuación genere un scatter plot entre la prediccion y el error.** \n",
    "\n",
    "Esto debería verse principalmente como ruido, ya que no debería haber correlación entre estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGLkv8khfOri"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DKwqMKlfQj5"
   },
   "source": [
    "Finalmente el último gráfico que realizaremos es el QQ Plot, que nos indicará la distribución del error a lo largo de los cuartiles.\n",
    "\n",
    "**Genere un qq plot con las predicciones realizadas.**\n",
    "(from statsmodels.graphics.gofplots import qqplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzprfV8FfyXR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YI13LHJqfzzd"
   },
   "source": [
    "En este caso los valores deben concentrarse sobre la linea diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9YH_amuf6-U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUtOtLRHkq3l"
   },
   "source": [
    "## 5. Importancia de las variables, Regresión Lineal\n",
    "\n",
    "En base a la arquitectura del modelo y utilizando los coeficientes del modelo, determine cuales son las 10 variables de mayor peso en el modelo y explique porque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFo9vfr9lGoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clG7lNcDgB9w"
   },
   "source": [
    "## 6. Preparación de datos para algoritmos basados en arboles\n",
    "\n",
    "Otra rama muy utilizada de modelos son aquellos basados en arboles de decisión, como Bagging, Random Forrest o Boosting. En nuestro caso utilizaremos una implementacion de Boosting por gradiente denominada XGBoost que es reconocida por producir muy buenos resultados.\n",
    "\n",
    "Dada la naturaleza de los árboles de decisión en este caso es necesario normalizar los datos. Para demostrarlo, entrene dos modelos con parametros por default, utilizando el dataset normalizado y sin normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zgvRXjciR2N",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxQzAc1LiTGT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfDQmTceiVQm"
   },
   "source": [
    "### Evaluacion del modelo, XGBoost\n",
    "\n",
    "Seleccione uno de los modelos, calcule las métricas y realize el análisis de residuos, similar al realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYem24gxiyk0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAlAg15ziz--"
   },
   "source": [
    "## 7. Importancia de las variables\n",
    "\n",
    "Utilize el metodo \"Feature Importance\" para determinar las 10 variables mas importante del modelo, verifique los diferentes criterios de calculo, seleccione uno y grafique sus coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcK1KRQClPil"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxP3JkxrmXdX"
   },
   "source": [
    "## 8. Clusterización\n",
    "\n",
    "Vamos a utilizar a la clusterización como método de preprocesamiento y posteriormente vamos a correr los modelos de predicción siguiendo el artículo:\n",
    "\n",
    "https://towardsdatascience.com/cluster-then-predict-for-classification-tasks-142fdfdc87d6\n",
    "\n",
    "\n",
    "Los pasos a seguir serían:\n",
    "\n",
    "1. Realizar la clusterización del conjunto de entrenamiento. Encontran la cantidad de cluster óptima con el elbow method.\n",
    "2. Realizar la predicción del cluster del conjunto de validación.\n",
    "3. Correr el mejor algoritmo de predicción de los puntos anteriores considerando el cluster como una feature\n",
    "4. Correr distintas predicciones para cada uno de los cluster: \n",
    "   + Dataset para el df[“clusters”] == 0 (clusters-0)\n",
    "   + Dataset para el df[“clusters”] == 1 (clusters-1)\n",
    "   +  ....\n",
    "   + Dataset para el df[“clusters”] == n (clusters-n)\n",
    "4. Comparar los resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPbRx7QfndgD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKucLSOol7Nv"
   },
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "A partir de todos los puntos anteriores exponga sus impresiones y conclusiones personales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
