{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "tutorial mitigar bias en word embeddings .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiranamejia/Diplodatos2020/blob/https%2Fcolab.research.google.com%2Fdrive%2F1GWE8PVGwvpo1ZxRket7xszJy3Q9DQABn%23scrollTo%3DyoJDoeIzTrqz/tutorial_mitigar_bias_en_word_embeddings_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TylXHnmHHPSm"
      },
      "source": [
        "# **Diagn√≥stico y mitigaci√≥n de sesgo de g√©nero en embeddings de palabras**\n",
        "\n",
        "## basado en el workshop https://learn.responsibly.ai/word-embedding\n",
        "\n",
        "y sobre el toolkit [`responsibly`](https://docs.responsibly.ai/) - para auditar y mitigar sesgo y obtener equidad en los sistemas de aprendizaje autom√°tico.\n",
        "\n",
        "# Descargos\n",
        "\n",
        "En este ejemplo nos enfocamos en sesgo de g√©nero simplific√°ndolo a un fen√≥meno binario, pero entendemos que se trata de una sobresimplificaci√≥n, una primera aproximaci√≥n a la familia de soluciones de mitigaci√≥n que requiere de una mayor complejidad para tratar los fen√≥menos de sesgo como construcciones sociales.\n",
        "\n",
        "Este material es un ejercicio puntual, no una perspectiva completa sobre sesgo en aprendizaje autom√°tico, equidad o inteligencia artificial responsable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4nFGQ75HPSn"
      },
      "source": [
        "# Configuraci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHn7LJEFHPSn"
      },
      "source": [
        "## Instalar `responsibly`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PNDdTweHPSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a895bb-2de4-47a4-d99b-2dbb9aa6348a"
      },
      "source": [
        "!pip install --user responsibly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: responsibly in /root/.local/lib/python3.6/site-packages (0.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from responsibly) (0.22.2.post1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from responsibly) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from responsibly) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.9 in /usr/local/lib/python3.6/dist-packages (from responsibly) (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from responsibly) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.24 in /usr/local/lib/python3.6/dist-packages (from responsibly) (4.41.1)\n",
            "Requirement already satisfied: matplotlib<3,>=2.2 in /root/.local/lib/python3.6/site-packages (from responsibly) (2.2.5)\n",
            "Requirement already satisfied: mlxtend<0.17,>=0.13 in /usr/local/lib/python3.6/dist-packages (from responsibly) (0.14.0)\n",
            "Requirement already satisfied: gensim>=3.7 in /root/.local/lib/python3.6/site-packages (from responsibly) (3.8.3)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.6/dist-packages (from responsibly) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from responsibly) (1.18.5)\n",
            "Requirement already satisfied: tabulate>=0.8 in /usr/local/lib/python3.6/dist-packages (from responsibly) (0.8.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19->responsibly) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->responsibly) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->responsibly) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3,>=2.2->responsibly) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3,>=2.2->responsibly) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3,>=2.2->responsibly) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend<0.17,>=0.13->responsibly) (50.3.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.7->responsibly) (4.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haXHrM7eHPSn"
      },
      "source": [
        "## Validar la instalaci√≥n de `responsibly`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx-k9YV9HPSn"
      },
      "source": [
        "import responsibly\n",
        "\n",
        "# deber√≠an obtener '0.1.2'\n",
        "responsibly.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwbS87m7HPSn"
      },
      "source": [
        "---\n",
        "\n",
        "Si est√°n trabajando en Colab, es normal que despu√©s de la instalaci√≥n tengan el error **`ModuleNotFoundError: No module named 'responsibly'`**.\n",
        "<br/> <br/>\n",
        "Reinicien el Kernel/Runtime (usen el men√∫ de arriba o el bot√≥n en la notebook), salteen la celda de instalaci√≥n (`!pip install --user responsibly`) y ejecuten la celda previa de vuelta. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aN-ZeM5HPSo"
      },
      "source": [
        "# Jugar con el embedding de Word2Vec\n",
        "\n",
        "Con el paquete [`responsibly`](http://docs.responsibly.ai) viene la funci√≥n [`responsibly.we.load_w2v_small`]() que devuelve un objeto [`KeyedVectors`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors) de [`gensim`](https://radimrehurek.com/gensim/). Este modelo fue entrenado con Google News - 100B tokens, vocabulario de 3 millones, vectores de 300 dimensiones, s√≥lo nos quedamos con el vocabulario en min√∫scula.\n",
        "\n",
        "Para m√°s informaci√≥n: [Word2Vec](https://code.google.com/archive/p/word2vec/) - \n",
        "\n",
        "## Propiedades B√°sicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MbuyNyFHPSo"
      },
      "source": [
        "# ignorar warnings\n",
        "# en general no queremos hacerlo pero ahora nos queremos enfocar en otra cosa\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2yChPuMHPSo"
      },
      "source": [
        "from responsibly.we import load_w2v_small\n",
        "\n",
        "w2v_small = load_w2v_small()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWa0pheRHPSo"
      },
      "source": [
        "# tamanio del vocabulario\n",
        "\n",
        "len(w2v_small.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilWEJIDHPSo"
      },
      "source": [
        "# obtener el vector de la palabra \"home\"\n",
        "\n",
        "print('home =', w2v_small['home'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6DWNcVsHPSo"
      },
      "source": [
        "# la dimensi√≥n del embedding de la palabra, en este caso, es 300\n",
        "\n",
        "len(w2v_small['home'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5i6Nd3EHPSo"
      },
      "source": [
        "# todas las palabras est√°n normalizadas (=tienen una norma igual a uno como vectores)\n",
        "\n",
        "from numpy.linalg import norm\n",
        "\n",
        "norm(w2v_small['home'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkBhxYuHPSo"
      },
      "source": [
        "# asegur√©monos que todos los vectores est√°n normalizados\n",
        "\n",
        "from numpy.testing import assert_almost_equal\n",
        "\n",
        "length_vectors = norm(w2v_small.vectors, axis=1)\n",
        "\n",
        "assert_almost_equal(actual=length_vectors,\n",
        "                    desired=1,\n",
        "                    decimal=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhCem0fsHPSo"
      },
      "source": [
        "## Medir la similitud entre palabras\n",
        "\n",
        "Usaremos el [coseno](https://es.wikipedia.org/wiki/Similitud_coseno) como medida de similitud (o distancia) entre palabras.\n",
        "- Mide el coseno del √°ngulo entre dos vectores.\n",
        "- Rango entre 1 (vectores id√©nticos) y -1 (vectores opuestos).\n",
        "- En Python, para vectores normalizados (arrays de Numpy), usar el operador `@`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-7nbBcsHPSo"
      },
      "source": [
        "w2v_small['cat'] @ w2v_small['cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwBriungHPSo"
      },
      "source": [
        "w2v_small['cat'] @ w2v_small['cats']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU2_chyBHPSo"
      },
      "source": [
        "from math import acos, degrees\n",
        "\n",
        "degrees(acos(w2v_small['cat'] @ w2v_small['cats']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmmYgVTyHPSo"
      },
      "source": [
        "w2v_small['cat'] @ w2v_small['dog']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ4QGX3QHPSo"
      },
      "source": [
        "degrees(acos(w2v_small['cat'] @ w2v_small['dog']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vAGtxd4HPSo"
      },
      "source": [
        "w2v_small['cat'] @ w2v_small['cow']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO9Ymx-CHPSo"
      },
      "source": [
        "degrees(acos(w2v_small['cat'] @ w2v_small['cow']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EXNejAxHPSo"
      },
      "source": [
        "w2v_small['cat'] @ w2v_small['graduated']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLR5i4QIHPSo"
      },
      "source": [
        "degrees(acos(w2v_small['cat'] @ w2v_small['graduated']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqHoqJnQHPSo"
      },
      "source": [
        "## Visualizaci√≥n del Word Embedding usando T-SNE \n",
        "\n",
        "<small>fuente: [Google's Seedbank](https://research.google.com/seedbank/seed/pretrained_word_embeddings)</small>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSaC_nyXHPSo"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from matplotlib import pylab as plt\n",
        "\n",
        "# take the most common words in the corpus between 200 and 600\n",
        "words = [word for word in w2v_small.index2word[200:600]]\n",
        "\n",
        "# convert the words to vectors\n",
        "embeddings = [w2v_small[word] for word in words]\n",
        "\n",
        "# perform T-SNE\n",
        "words_embedded = TSNE(n_components=2).fit_transform(embeddings)\n",
        "\n",
        "# ... and visualize!\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i, label in enumerate(words):\n",
        "    x, y = words_embedded[i, :]\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
        "                 ha='right', va='bottom', size=11)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2laNOxSAHPSo"
      },
      "source": [
        "### Extra: [Tensorflow Embedding Projector](http://projector.tensorflow.org)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0orOF4LHPSo"
      },
      "source": [
        "## Palabras m√°s semejantes\n",
        "\n",
        "Cu√°les son las palabras m√°s semejantes a una determinada palabra?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr8o2o_THPSo"
      },
      "source": [
        "w2v_small.most_similar('cat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQLpS8IlHPSp"
      },
      "source": [
        "### EXTRA: Cu√°l es la palabra que desentona?\n",
        "\n",
        "Dada una lista de palabras, cu√°l desentona? Es decir, cu√°l es la que est√° m√°s lejos de la media de palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr3hQvF0HPSp"
      },
      "source": [
        "w2v_small.doesnt_match('breakfast cereal dinner lunch'.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT_RDdLFHPSp"
      },
      "source": [
        "## Suma de palabras\n",
        "\n",
        "![](https://github.com/ResponsiblyAI/word-embedding/blob/master/images/vector-addition.png?raw=1)\n",
        "\n",
        "<small>fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:Vector_add_scale.svg)</small>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safkv9RCHPSp"
      },
      "source": [
        "# nature + science = ?\n",
        "\n",
        "w2v_small.most_similar(positive=['nature', 'science'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgRMunP4HPSp"
      },
      "source": [
        "## Analog√≠a de vectores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo1smCA6HPSp"
      },
      "source": [
        "![](https://www.tensorflow.org/images/linear-relationships.png)\n",
        "<small>fuente: [Documentaci√≥n de Tensorflow](https://www.tensorflow.org/tutorials/representation/word2vec)</small>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMEgOEhgHPSp"
      },
      "source": [
        "# man:king :: woman:?\n",
        "# king - man + woman = ?\n",
        "\n",
        "w2v_small.most_similar(positive=['king', 'woman'],\n",
        "                       negative=['man'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DudawGFKHPSp"
      },
      "source": [
        "w2v_small.most_similar(positive=['big', 'smaller'],\n",
        "                       negative=['small'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja00u1VDHPSp"
      },
      "source": [
        "## La direcci√≥n de un embedding puede verse como una relaci√≥n\n",
        "\n",
        "# $\\overrightarrow{she} - \\overrightarrow{he}$\n",
        "# $\\overrightarrow{smaller} - \\overrightarrow{small}$\n",
        "# $\\overrightarrow{Spain} - \\overrightarrow{Madrid}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9OBIpv2HPSp"
      },
      "source": [
        "# Diagnosticamos sesgo de g√©nero en embeddings\n",
        "\n",
        "Bolukbasi Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam T. Kalai. [Man is to computer programmer as woman is to homemaker? debiasing word embeddings](https://arxiv.org/abs/1607.06520). NIPS 2016.\n",
        "\n",
        "¬øC√≥mo afecta el sesgo de g√©nero en embeddings en el contexto de aplicaciones downstream?\n",
        "\n",
        "![](https://github.com/ResponsiblyAI/word-embedding/blob/master/images/examples-gender-bias-nlp.png?raw=1)\n",
        "\n",
        "<small>fuente: Sun, T., Gaut, A., Tang, S., Huang, Y., ElSherief, M., Zhao, J., ... & Wang, W. Y. (2019). [Mitigating Gender Bias in Natural Language Processing: Literature Review](https://arxiv.org/pdf/1906.08976.pdf). arXiv preprint arXiv:1906.08976.</small>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPSnOYQIHPSp"
      },
      "source": [
        "## Probemos algunas propiedades con expresiones que sabemos que est√°n fuertemente marcadas por el g√©nero\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEDgqRlFHPSp"
      },
      "source": [
        "# she:sister :: he:?\n",
        "# sister - she + he = ?\n",
        "\n",
        "w2v_small.most_similar(positive=['sister', 'he'],\n",
        "                       negative=['she'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLRbogzEHPSp"
      },
      "source": [
        "```\n",
        "queen-king\n",
        "waitress-waiter\n",
        "sister-brother\n",
        "mother-father\n",
        "ovarian_cancer-prostate_cancer\n",
        "convent-monastery\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlErzh68HPSp"
      },
      "source": [
        "w2v_small.most_similar(positive=['nurse', 'he'],\n",
        "                       negative=['she'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74Iz-14HPSp"
      },
      "source": [
        "```\n",
        "sewing-carpentry\n",
        "nurse-doctor\n",
        "blond-burly\n",
        "giggle-chuckle\n",
        "sassy-snappy\n",
        "volleyball-football\n",
        "register_nurse-physician\n",
        "interior_designer-architect\n",
        "feminism-conservatism\n",
        "vocalist-guitarist\n",
        "diva-superstar\n",
        "cupcakes-pizzas\n",
        "housewife-shopkeeper\n",
        "softball-baseball\n",
        "cosmetics-pharmaceuticals\n",
        "petite-lanky\n",
        "charming-affable\n",
        "hairdresser-barber\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvfPt1T-HPSp"
      },
      "source": [
        "Parece que el m√©todo de generar analog√≠as no es la forma m√°s adecuada de observar sesgo en los embeddings, por la paradoja del observador: introduce sesgo, fuerza la producci√≥n de estereotipos de g√©nero!\n",
        "\n",
        "Nissim, M., van Noord, R., van der Goot, R. (2019). [Fair is Better than Sensational: Man is to Doctor as Woman is to Doctor](https://arxiv.org/abs/1905.09866).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2F_l7OeHPSp"
      },
      "source": [
        "## Qu√© s√≠ nos da la analog√≠a? La direcci√≥n del g√©nero!\n",
        "\n",
        "# $\\overrightarrow{she} - \\overrightarrow{he}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjRzqqbHPSp"
      },
      "source": [
        "gender_direction = w2v_small['she'] - w2v_small['he']\n",
        "\n",
        "gender_direction /= norm(gender_direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw3Xed-kHPSp"
      },
      "source": [
        "gender_direction @ w2v_small['architect']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Ip0nTKHPSp"
      },
      "source": [
        "gender_direction @ w2v_small['interior_designer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RuU3hbEHPSp"
      },
      "source": [
        "Con todos los recaudos de saber que estamos sobresimplificando el fen√≥meno, podemos ver que la palabra *architect* aparece en m√°s contextos con *he* que con *she*, y viceversa para *interior designer*.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8uZ6qLQHPSp"
      },
      "source": [
        "Bas√°ndonos en esta propiedad, podemos calcular la direcci√≥n del g√©nero usano varios pares de palabras que sabemos que est√°n fuertemente marcadas para g√©nero.:\n",
        "\n",
        "- woman - man\n",
        "- girl - boy\n",
        "- she - he\n",
        "- mother - father\n",
        "- daughter - son\n",
        "- gal - guy\n",
        "- female - male\n",
        "- her - his\n",
        "- herself - himself\n",
        "- Mary - John"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYl3D_ATHPSp"
      },
      "source": [
        "## Prueben con algunas palabras\n",
        "Reflexi√≥n: ¬øest√°n haciendo an√°lisis exploratorio o evaluaci√≥n sistem√°tica?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCGf0oHBHPSp"
      },
      "source": [
        "gender_direction @ w2v_small['word']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshpmrI9HPSp"
      },
      "source": [
        "Proyecciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhfOAPsTHPSp"
      },
      "source": [
        "from responsibly.we import GenderBiasWE\n",
        "\n",
        "w2v_small_gender_bias = GenderBiasWE(w2v_small, only_lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7OjvenQHPSp"
      },
      "source": [
        "w2v_small_gender_bias.positive_end, w2v_small_gender_bias.negative_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBSW9vuSHPSq"
      },
      "source": [
        "# direcci√≥n del g√©nero\n",
        "w2v_small_gender_bias.direction[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WxA6tfvHPSq"
      },
      "source": [
        "from responsibly.we.data import BOLUKBASI_DATA\n",
        "\n",
        "neutral_profession_names = BOLUKBASI_DATA['gender']['neutral_profession_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSOGF5BHPSq"
      },
      "source": [
        "neutral_profession_names[:8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzjYnRJ8HPSq"
      },
      "source": [
        "Nota: `actor` est√° en la lista de nombres de profesi√≥n neutros, y no`actress` porque parece que el uso de la palabra ha cambiado con el tiempo y ahora es m√°s neutro, en comparaci√≥n por ejemplo con  waiter-waitress (ver [Wikipedia - The term Actress](https://en.wikipedia.org/wiki/Actor#The_term_actress))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI93U0JlHPSq"
      },
      "source": [
        "len(neutral_profession_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JS7UZjyHPSs"
      },
      "source": [
        "# the same of using the @ operator on the bias direction\n",
        "\n",
        "w2v_small_gender_bias.project_on_direction(neutral_profession_names[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDPo28WyHPSs"
      },
      "source": [
        "Visualicemos las proyecciones de las profesiones (neutras y espec√≠ficas) en la direcci√≥n del g√©nero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zEnirv55HPSt"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "w2v_small_gender_bias.plot_projection_scores(n_extreme=20, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z_VCT-eHPSt"
      },
      "source": [
        "EXTRA: Demo - Visualizando sesgo de g√©nero con [Nubes de palabras](http://wordbias.umiacs.umd.edu/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtcH2sX_HPSt"
      },
      "source": [
        "Las proyecciones en la direcci√≥n de g√©nero de las palabras de profesiones se corresponden con datos de ocupaci√≥n desglosados por g√©nero, seg√∫n se puede ver en el porcentaje de mujeres en diversas profesiones seg√∫n la encuesta de poblaci√≥n de 2017 del Labor Force Statistics: https://arxiv.org/abs/1804.06876"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZoIxVJ4HPSt"
      },
      "source": [
        "from operator import itemgetter  # üõ†Ô∏è For idiomatic sorting in Python\n",
        "\n",
        "from responsibly.we.data import OCCUPATION_FEMALE_PRECENTAGE\n",
        "\n",
        "sorted(OCCUPATION_FEMALE_PRECENTAGE.items(), key=itemgetter(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSrQIXF7HPSt"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(10, 8))\n",
        "\n",
        "w2v_small_gender_bias.plot_factual_association(ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQw3uMaDHPSt"
      },
      "source": [
        "Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). [Word embeddings quantify 100 years of gender and ethnic stereotypes](https://www.pnas.org/content/pnas/115/16/E3635.full.pdf). Proceedings of the National Academy of Sciences, 115(16), E3635-E3644.\n",
        "\n",
        "![](https://github.com/ResponsiblyAI/word-embedding/blob/master/images/gender-bias-over-decades.png?raw=1)\n",
        "\n",
        "<small>Data: Google Books/Corpus of Historical American English (COHA)</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kve5HaIUHPSt"
      },
      "source": [
        "## Medici√≥n directa del sesgo\n",
        "\n",
        "1. Proyectamos cada uno de los nombres de profesi√≥n neutros en la direcci√≥n de g√©nero\n",
        "2. Calculamos el valor absoluto de cada proyecci√≥n\n",
        "3. Lo promediamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEN5PVPsHPSu"
      },
      "source": [
        "# funci√≥n de alto nivel en responsibly\n",
        "\n",
        "w2v_small_gender_bias.calc_direct_bias()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgtF2eUqHPSu"
      },
      "source": [
        "# qu√© hace responsibly internamente:\n",
        "\n",
        "neutral_profession_projections = [w2v_small[word] @ w2v_small_gender_bias.direction\n",
        "                                  for word in neutral_profession_names]\n",
        "\n",
        "abs_neutral_profession_projections = [abs(proj) for proj in neutral_profession_projections]\n",
        "\n",
        "sum(abs_neutral_profession_projections) / len(abs_neutral_profession_projections)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZoPjpEeHPSu"
      },
      "source": [
        "**Atenci√≥n** la medici√≥n directa de sesgo est√° haciendo asunciones fuertes sobre las palabras neutras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwoxH_RgHPSu"
      },
      "source": [
        "## 5.10 - [EXTRA] Medici√≥n indirecta del sesgo\n",
        "Semejanza por proyecci√≥n en la misma \"direcci√≥n de g√©nero\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pamry1hmHPSv"
      },
      "source": [
        "w2v_small_gender_bias.generate_closest_words_indirect_bias('softball',\n",
        "                                                           'football')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlS0ydglHPSv"
      },
      "source": [
        "# Mitigar sesgo\n",
        "\n",
        "> We intentionally do not reference the resulting embeddings as \"debiased\" or free from all gender bias, and\n",
        "prefer the term \"mitigating bias\" rather that \"debiasing,\" to guard against the misconception that the resulting\n",
        "embeddings are entirely \"safe\" and need not be critically evaluated for bias in downstream tasks. <small>James-Sorenson, H., & Alvarez-Melis, D. (2019). [Probabilistic Bias Mitigation in Word Embeddings](https://arxiv.org/pdf/1910.14497.pdf). arXiv preprint arXiv:1910.14497.</small>\n",
        "\n",
        "\n",
        "## Neutralizar\n",
        "\n",
        "Si neutralizamos, vamos a eliminar la proyecci√≥n de g√©nero de todas las palabras excepto las de g√©nero neutro, y despu√©s normalizamos.\n",
        "\n",
        "**Atenci√≥n** un prerequisito fuerte es tener la lista de palabras fuertemente marcadas para g√©nero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGGDnQHTHPSv"
      },
      "source": [
        "w2v_small_gender_debias = w2v_small_gender_bias.debias(method='neutralize', inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVoPZ9qvHPSv"
      },
      "source": [
        "print('home:',\n",
        "      'before =', w2v_small_gender_bias.model['home'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['home'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pum8xVStHPSv"
      },
      "source": [
        "print('man:',\n",
        "      'before =', w2v_small_gender_bias.model['man'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiN3so-cHPSv"
      },
      "source": [
        "print('woman:',\n",
        "      'before =', w2v_small_gender_bias.model['woman'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSbuQ_0nHPSv"
      },
      "source": [
        "w2v_small_gender_debias.calc_direct_bias()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nviSfKo0HPSv"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "w2v_small_gender_debias.plot_projection_scores(n_extreme=20, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytG7tYD6HPSv"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(10, 8))\n",
        "\n",
        "w2v_small_gender_debias.plot_factual_association(ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D72h6h_-HPSv"
      },
      "source": [
        "## [EXTRA] Ecualizar\n",
        "\n",
        "Las palabras en la lista de palabras marcadas para g√©nero (como por ejemplo `man` y `woman`) pueden tener una proyecci√≥n diferente en la direcci√≥n de g√©nero. Eso puede resultar en una similitud diferente a palabras neutras, como `kitchen`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NpdcrJVHPSv"
      },
      "source": [
        "w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.model['kitchen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSEfiZPHPSv"
      },
      "source": [
        "w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.model['kitchen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEwqwZXoHPSv"
      },
      "source": [
        "BOLUKBASI_DATA['gender']['equalize_pairs'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vELxkXLHPSv"
      },
      "source": [
        "## Eliminaci√≥n de sesgo dura: Neutralizar y Ecualizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm9XmdjiHPSw"
      },
      "source": [
        "w2v_small_gender_debias = w2v_small_gender_bias.debias(method='hard', inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScM9OhHwHPSw"
      },
      "source": [
        "print('home:',\n",
        "      'before =', w2v_small_gender_bias.model['home'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['home'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLS5X6WHPSx"
      },
      "source": [
        "print('man:',\n",
        "      'before =', w2v_small_gender_bias.model['man'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YxQoXzOHPSx"
      },
      "source": [
        "print('woman:',\n",
        "      'before =', w2v_small_gender_bias.model['woman'] @ w2v_small_gender_bias.direction,\n",
        "      'after = ', w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.direction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv_ioBbkHPSx"
      },
      "source": [
        "w2v_small_gender_debias.calc_direct_bias()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7TlMzRUHPSx"
      },
      "source": [
        "w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.model['kitchen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtftVhxHPSx"
      },
      "source": [
        "w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.model['kitchen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLwPjbgIHPSx"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "w2v_small_gender_debias.plot_projection_scores(n_extreme=20, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYfDqt5aHPSx"
      },
      "source": [
        "Despu√©s de mitigar el sesgo, el rendimiento del embedding resultante en benchmarks est√°ndares no se ve fuertemente afectado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3f3WQhgHPSx"
      },
      "source": [
        "w2v_small_gender_bias.evaluate_word_embedding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB_b9z16HPSx"
      },
      "source": [
        "w2v_small_gender_debias.evaluate_word_embedding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5krvKnHPS1"
      },
      "source": [
        "# Explorar otros tipos de sesgo en word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hblQa1vKHPS1"
      },
      "source": [
        "### Sesgo racial\n",
        "\n",
        "Usaremos la clase [`responsibly.we.BiasWordEmbedding`](http://docs.responsibly.ai/word-embedding-bias.html#ethically.we.bias.BiasWordEmbedding). `GenderBiasWE` es una subclase de `BiasWordEmbedding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXOGwjCgHPS1"
      },
      "source": [
        "from responsibly.we import BiasWordEmbedding\n",
        "\n",
        "w2v_small_racial_bias = BiasWordEmbedding(w2v_small, only_lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_m-sCQPHPS2"
      },
      "source": [
        "Identificar la direcci√≥n racial usando el m√©todo `sum`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NgemvQPHPS2"
      },
      "source": [
        "white_common_names = ['Emily', 'Anne', 'Jill', 'Allison', 'Laurie', 'Sarah', 'Meredith', 'Carrie',\n",
        "                      'Kristen', 'Todd', 'Neil', 'Geoffrey', 'Brett', 'Brendan', 'Greg', 'Matthew',\n",
        "                      'Jay', 'Brad']\n",
        "\n",
        "black_common_names = ['Aisha', 'Keisha', 'Tamika', 'Lakisha', 'Tanisha', 'Latoya', 'Kenya', 'Latonya',\n",
        "                      'Ebony', 'Rasheed', 'Tremayne', 'Kareem', 'Darnell', 'Tyrone', 'Hakim', 'Jamal',\n",
        "                      'Leroy', 'Jermaine']\n",
        "\n",
        "w2v_small_racial_bias._identify_direction('Whites', 'Blacks',\n",
        "                                          definitional=(white_common_names, black_common_names),\n",
        "                                          method='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDuYsHv7HPS2"
      },
      "source": [
        "Usar los nombres de profesi√≥n neutros para medir el sesgo racial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQxxl7LIHPS2"
      },
      "source": [
        "neutral_profession_names = BOLUKBASI_DATA['gender']['neutral_profession_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSVyfTklHPS2"
      },
      "source": [
        "neutral_profession_names[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGMT4tNfHPS2"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "w2v_small_racial_bias.plot_projection_scores(neutral_profession_names, n_extreme=20, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPn1vjxZHPS2"
      },
      "source": [
        "Calcular la medida directa de sesgo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2zrnHd6HPS2"
      },
      "source": [
        "# Your Code Here..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJFRjlJ1HPS2"
      },
      "source": [
        "Sigan explorando el sesgo racial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toREKl5YHPS2"
      },
      "source": [
        "# Your Code Here..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuF8ZOFWHPS3"
      },
      "source": [
        "# Recursos\n",
        "\n",
        "## [Doing Data Science Responsibly - Resources](https://handbook.responsibly.ai/appendices/resources.html)\n",
        "\n",
        "In particular:\n",
        "\n",
        "- CVPR 2020 - [FATE Tutorial](https://youtu.be/-xGvcDzvi7Q) [Video]\n",
        "\n",
        "- fast.ai - [Algorithmic Bias (NLP video 16)](https://youtu.be/pThqge9QDn8) [Video]\n",
        "\n",
        "-  Solon Barocas, Moritz Hardt, Arvind Narayanan - [Fairness and machine learning - Limitations and Opportunities](https://fairmlbook.org/) [Textbook]\n",
        "\n",
        "\n",
        "\n",
        "## Non-Technical Overview with More Downstream Application Examples\n",
        "- [Google - Text Embedding Models Contain Bias. Here's Why That Matters.](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html)\n",
        "- [Kai-Wei Chang (UCLA) - What It Takes to Control Societal Bias in Natural Language Processing](https://www.youtube.com/watch?v=RgcXD_1Cu18)\n",
        "- Sun, T., Gaut, A., Tang, S., Huang, Y., ElSherief, M., Zhao, J., ... & Wang, W. Y. (2019). [Mitigating Gender Bias in Natural Language Processing: Literature Review](https://arxiv.org/pdf/1906.08976.pdf). arXiv preprint arXiv:1906.08976.\n",
        "\n",
        "## Additional Related Work\n",
        "\n",
        "- **Understanding Bias**\n",
        "    - Ethayarajh, K., Duvenaud, D., & Hirst, G. (2019, July). [Understanding Undesirable Word Embedding Associations](https://arxiv.org/pdf/1908.06361.pdf). In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 1696-1705). - **Including critical analysis of the current metrics and debiasing methods (quite technical)**\n",
        "\n",
        "  - Brunet, M. E., Alkalay-Houlihan, C., Anderson, A., & Zemel, R. (2019, May). [Understanding the Origins of Bias in Word Embeddings](https://arxiv.org/pdf/1810.03611.pdf). In International Conference on Machine Learning (pp. 803-811).\n",
        "\n",
        "\n",
        "- **Discovering Biases**\n",
        "  - Swinger, N., De-Arteaga, M., Heffernan IV, N. T., Leiserson, M. D., & Kalai, A. T. (2019, January). [What are the biases in my word embedding?](https://arxiv.org/pdf/1812.08769.pdf). In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (pp. 305-311). ACM.\n",
        "    Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories\n",
        "  \n",
        "  - Chaloner, K., & Maldonado, A. (2019, August). [Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories](https://www.aclweb.org/anthology/W19-3804). In Proceedings of the First Workshop on Gender Bias in Natural Language Processing (pp. 25-32).\n",
        "\n",
        "\n",
        "- **Fairness in Classification**\n",
        "  - Prost, F., Thain, N., & Bolukbasi, T. (2019, August). [Debiasing Embeddings for Reduced Gender Bias in Text Classification](https://arxiv.org/pdf/1908.02810.pdf). In Proceedings of the First Workshop on Gender Bias in Natural Language Processing (pp. 69-75).\n",
        "  \n",
        "  - Romanov, A., De-Arteaga, M., Wallach, H., Chayes, J., Borgs, C., Chouldechova, A., ... & Kalai, A. (2019, June). [What's in a Name? Reducing Bias in Bios without Access to Protected Attributes](https://arxiv.org/pdf/1904.05233.pdf). In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4187-4195).\n",
        "\n",
        "\n",
        "- **Other**\n",
        "  \n",
        "  - Zhao, J., Wang, T., Yatskar, M., Cotterell, R., Ordonez, V., & Chang, K. W. (2019, June). [Gender Bias in Contextualized Word Embeddings](https://arxiv.org/pdf/1904.03310.pdf). In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 629-634). [slides](https://jyzhao.net/files/naacl19.pdf)\n",
        "\n",
        "  - Zhou, P., Shi, W., Zhao, J., Huang, K. H., Chen, M., & Chang, K. W. [Analyzing and Mitigating Gender Bias in Languages with Grammatical Gender and Bilingual Word Embeddings](https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/47_aisg_icml2019.pdf). ICML 2019 - AI for Social Good. [Poster](https://aiforsocialgood.github.io/icml2019/accepted/track1/posters/47_aisg_icml2019.pdf)\n",
        "\n",
        "- Zhao, J., Mukherjee, S., Hosseini, S., Chang, K. W., & Awadallah, A. [Gender Bias in Multilingual Embeddings](https://www.researchgate.net/profile/Subhabrata_Mukherjee/publication/340660062_Gender_Bias_in_Multilingual_Embeddings/links/5e97428692851c2f52a6200a/Gender-Bias-in-Multilingual-Embeddings.pdf).\n",
        "\n",
        "\n",
        "##### Complete example of using `responsibly` with Word2Vec, GloVe and fastText: http://docs.responsibly.ai/notebooks/demo-gender-bias-words-embedding.html\n",
        "\n",
        "\n",
        "## Bias in NLP\n",
        "\n",
        "Around dozen of papers on this field until 2019, but nowdays plenty of work is done. Two venues from back then:\n",
        "- [1st ACL Workshop on Gender Bias for Natural Language Processing](https://genderbiasnlp.talp.cat/)\n",
        "- [NAACL 2019](https://naacl2019.org/)\n"
      ]
    }
  ]
}